Different: args, Namespace(num_layers=40, encoder_num_layers=40, decoder_num_layers=None, hidden_size=5120, ffn_hidden_size=13824, num_attention_heads=40, kv_channels=128, group_query_attention=True, num_query_groups=40, max_position_embeddings=4096, position_embedding_type='rope', use_rotary_position_embeddings=True, rotary_percent=1.0, rotary_seq_len_interpolation_factor=None, add_position_embedding=False, make_vocab_size_divisible_by=128, normalization='RMSNorm', norm_epsilon=1e-05, apply_layernorm_1p=False, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=True, onnx_safe=None, bert_binary_head=True, num_experts=None, untie_embeddings_and_output_weights=True, attention_dropout=0.0, hidden_dropout=0.0, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=1024, rampup_batch_size=None, recompute_granularity='selective', check_for_nan_in_loss_and_grad=True, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=None, profile=False, profile_step_start=10, profile_step_end=12, profile_ranks=[0], wandb_entity='prj-jalm', wandb_name='llama-2-13b-base-extended-llm-jp-a100-16node-128gpu-4096s-DP=16-TP=2-PP=4-BS=1024-LR=1e-4-MINLR=3.3e-6-WARMUP=1000-WD=0.1-GC=1', wandb_project='Llama-2-13B', wandb_id=None, use_mpi=True, train_iters=25000, train_samples=None, log_interval=1, exit_interval=None, exit_duration_in_mins=None, exit_signal_handler=False, tensorboard_dir=None, masked_softmax_fusion=False, bias_gelu_fusion=False, bias_dropout_fusion=True, use_flash_attn=True, add_bias_linear=False, optimizer='adam', dataloader_type='single', async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=True, gradient_accumulation_fusion=True, expert_parallel=False, seed=1234, data_parallel_random_init=False, init_method_std=0.02, init_method_xavier_uniform=False, lr=0.0001, lr_decay_style='cosine', lr_decay_iters=25000, lr_decay_samples=None, lr_warmup_fraction=None, lr_warmup_iters=1000, lr_warmup_samples=0, lr_warmup_init=0.0, min_lr=3.3e-06, override_opt_param_scheduler=False, use_checkpoint_opt_param_scheduler=False, save='/bb/llm/gaf51275/llama/checkpoints/llama-2-13b-base-extended-megatron/llm-jp/tp2-pp4', save_interval=500, no_save_optim=None, no_save_rng=None, load='/bb/llm/gaf51275/llama/llama-megatron-convert-checkpoint-hf/Llama-2-13b-extended/okazaki_lab_cc/tp2-pp4', no_load_optim=True, no_load_rng=True, finetune=False, perform_initialization=True, use_checkpoint_args=True, exit_on_missing_checkpoint=False, fp16=False, bf16=True, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=True, fp16_lm_cross_entropy=False, tensor_model_parallel_size=2, pipeline_model_parallel_size=4, pipeline_model_parallel_split_rank=None, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, overlap_grad_reduce=False, delay_grad_reduce=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=True, eval_iters=10, eval_interval=100, skip_train=False, data_path=['23610357658', '/groups/gaf51275/llama/datasets/llm-jp-corpus_v1.0.1_okazaki_cc_nfkc_16k_aligned_8/llm_jp_v101_ja_cc_0_text_document', '23603672312', '/groups/gaf51275/llama/datasets/llm-jp-corpus_v1.0.1_okazaki_cc_nfkc_16k_aligned_8/llm_jp_v101_ja_cc_1_text_document', '23604487935', '/groups/gaf51275/llama/datasets/llm-jp-corpus_v1.0.1_okazaki_cc_nfkc_16k_aligned_8/llm_jp_v101_ja_cc_2_text_document', '17508938222', '/groups/gaf51275/llama/datasets/llm-jp-corpus_v1.0.1_okazaki_cc_nfkc_16k_aligned_8/llm_jp_v101_ja_cc_3_text_document', '1672543873', '/bb/llm/gaf51275/llama/datasets/okazaki_lab_cc_1500_okazaki_lab_cc_nfkc_16k_aligned_8/ja_wiki_merged_train_text_document', '5000000000', '/bb/llm/gaf51275/llama/datasets/okazaki_lab_cc_1500_okazaki_lab_cc_nfkc_16k_aligned_8/lumi_en_arxiv_merged_text_document', '5000000000', '/bb/llm/gaf51275/llama/datasets/okazaki_lab_cc_1500_okazaki_lab_cc_nfkc_16k_aligned_8/lumi_en_falcon_merged_threadripper-3960x_8_text_document'], split='949,50,1', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file=None, merge_file=None, vocab_extra_ids=0, seq_length=4096, encoder_seq_length=4096, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=2, tokenizer_type='Llama2Tokenizer', tokenizer_model='/bb/llm/gaf51275/jalm/jalm-tokenizer-private/tokenizer/jalm_llama_okazaki_lab_cc_nfkc_16k_aligned_8/merged_tokenizer_sp/jalm_llama.model', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1000, log_timers_to_tensorboard=False, log_batch_size_to_tensorboard=False, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8=None, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, transformer_impl='local', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, model_spec=None, rank=0, world_size=128, iteration=1, padded_vocab_size=43176, transformer_pipeline_model_parallel_size=4, data_parallel_size=16, virtual_pipeline_model_parallel_size=None, params_dtype=torch.bfloat16, consumed_train_samples=5120000, consumed_valid_samples=512000, variable_seq_lengths=False, model_type=<ModelType.encoder_or_decoder: 1>, allow_transformer_engine=True, do_train=1, do_valid=1, do_test=1, curr_iteration=4999), Namespace(num_layers=40, encoder_num_layers=40, decoder_num_layers=None, hidden_size=5120, ffn_hidden_size=13824, num_attention_heads=40, kv_channels=128, group_query_attention=True, num_query_groups=40, max_position_embeddings=4096, position_embedding_type='rope', use_rotary_position_embeddings=True, rotary_percent=1.0, rotary_seq_len_interpolation_factor=None, add_position_embedding=False, make_vocab_size_divisible_by=128, normalization='RMSNorm', norm_epsilon=1e-05, apply_layernorm_1p=False, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=True, onnx_safe=None, bert_binary_head=True, num_experts=None, untie_embeddings_and_output_weights=True, attention_dropout=0.0, hidden_dropout=0.0, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=1024, rampup_batch_size=None, recompute_granularity='selective', check_for_nan_in_loss_and_grad=True, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=None, profile=False, profile_step_start=10, profile_step_end=12, profile_ranks=[0], wandb_entity='prj-jalm', wandb_name='llama-2-13b-base-extended-llm-jp-a100-16node-128gpu-4096s-DP=16-TP=2-PP=4-BS=1024-LR=1e-4-MINLR=3.3e-6-WARMUP=1000-WD=0.1-GC=1', wandb_project='Llama-2-13B', wandb_id=None, use_mpi=True, train_iters=25000, train_samples=None, log_interval=1, exit_interval=None, exit_duration_in_mins=None, exit_signal_handler=False, tensorboard_dir=None, masked_softmax_fusion=False, bias_gelu_fusion=False, bias_dropout_fusion=True, use_flash_attn=True, add_bias_linear=False, optimizer='adam', dataloader_type='single', async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=True, gradient_accumulation_fusion=True, expert_parallel=False, seed=1234, data_parallel_random_init=False, init_method_std=0.02, init_method_xavier_uniform=False, lr=0.0001, lr_decay_style='cosine', lr_decay_iters=25000, lr_decay_samples=None, lr_warmup_fraction=None, lr_warmup_iters=1000, lr_warmup_samples=0, lr_warmup_init=0.0, min_lr=3.3e-06, override_opt_param_scheduler=False, use_checkpoint_opt_param_scheduler=False, save='/bb/llm/gaf51275/llama/checkpoints/llama-2-13b-base-extended-megatron/llm-jp/tp2-pp4', save_interval=500, no_save_optim=None, no_save_rng=None, load='/bb/llm/gaf51275/llama/checkpoints/llama-2-13b-base-extended-megatron/llm-jp/tp2-pp4', no_load_optim=None, no_load_rng=None, finetune=False, perform_initialization=True, use_checkpoint_args=True, exit_on_missing_checkpoint=False, fp16=False, bf16=True, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=True, fp16_lm_cross_entropy=False, tensor_model_parallel_size=2, pipeline_model_parallel_size=4, pipeline_model_parallel_split_rank=None, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, overlap_grad_reduce=False, delay_grad_reduce=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=True, eval_iters=10, eval_interval=100, skip_train=False, data_path=['23610357658', '/groups/gaf51275/llama/datasets/llm-jp-corpus_v1.0.1_okazaki_cc_nfkc_16k_aligned_8/llm_jp_v101_ja_cc_0_text_document', '23603672312', '/groups/gaf51275/llama/datasets/llm-jp-corpus_v1.0.1_okazaki_cc_nfkc_16k_aligned_8/llm_jp_v101_ja_cc_1_text_document', '23604487935', '/groups/gaf51275/llama/datasets/llm-jp-corpus_v1.0.1_okazaki_cc_nfkc_16k_aligned_8/llm_jp_v101_ja_cc_2_text_document', '17508938222', '/groups/gaf51275/llama/datasets/llm-jp-corpus_v1.0.1_okazaki_cc_nfkc_16k_aligned_8/llm_jp_v101_ja_cc_3_text_document', '1672543873', '/bb/llm/gaf51275/llama/datasets/okazaki_lab_cc_1500_okazaki_lab_cc_nfkc_16k_aligned_8/ja_wiki_merged_train_text_document', '5000000000', '/bb/llm/gaf51275/llama/datasets/okazaki_lab_cc_1500_okazaki_lab_cc_nfkc_16k_aligned_8/lumi_en_arxiv_merged_text_document', '5000000000', '/bb/llm/gaf51275/llama/datasets/okazaki_lab_cc_1500_okazaki_lab_cc_nfkc_16k_aligned_8/lumi_en_falcon_merged_threadripper-3960x_8_text_document'], split='949,50,1', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file=None, merge_file=None, vocab_extra_ids=0, seq_length=4096, encoder_seq_length=4096, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=2, tokenizer_type='Llama2Tokenizer', tokenizer_model='/bb/llm/gaf51275/jalm/jalm-tokenizer-private/tokenizer/jalm_llama_okazaki_lab_cc_nfkc_16k_aligned_8/merged_tokenizer_sp/jalm_llama.model', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1000, log_timers_to_tensorboard=False, log_batch_size_to_tensorboard=False, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8=None, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, transformer_impl='local', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, model_spec=None, rank=0, world_size=128, iteration=9500, padded_vocab_size=43176, transformer_pipeline_model_parallel_size=4, data_parallel_size=16, virtual_pipeline_model_parallel_size=None, params_dtype=torch.bfloat16, consumed_train_samples=15360000, consumed_valid_samples=1536000, variable_seq_lengths=False, model_type=<ModelType.encoder_or_decoder: 1>, allow_transformer_engine=True, do_train=1, do_valid=1, do_test=1, curr_iteration=14999)
Different: iteration, 5000, 15000
Traceback (most recent call last):
  File "/bb/1/llm/gaf51275/llama/Megatron-LM/scripts/abci/checkpoint_check/is_same.py", line 32, in <module>
    if not compare_values(checkpoint_1[key], checkpoint_2[key]):
  File "/bb/1/llm/gaf51275/llama/Megatron-LM/scripts/abci/checkpoint_check/is_same.py", line 21, in compare_values
    return value1 == value2
RuntimeError: Boolean value of Tensor with more than one value is ambiguous
